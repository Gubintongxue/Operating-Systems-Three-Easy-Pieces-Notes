### 第十七章 空闲空间管理

在这一章中，我们暂时搁置虚拟内存的讨论，转而探讨所有内存管理系统中的一个基本方面——空闲空间管理。无论是用户级的内存分配库（如 `malloc()`）还是操作系统自身的内存管理系统，都需要有效地管理空闲空间。

#### 关键问题：如何管理空闲空间

当要管理的空间大小不固定时，管理空闲空间就变得复杂且富有挑战性。外部碎片是一个核心问题：空闲空间被切割成不同大小的小块，这些碎片可能导致无法满足后续请求，即使总的空闲空间超过请求的大小。

**示例**： 例如，如果内存中有两个各为10字节的空闲块，而应用程序请求一个15字节的内存块，尽管总空闲空间为20字节，但由于没有足够大的连续空闲块，分配请求仍然会失败。

**问题**：如何管理空闲空间以最小化碎片，同时满足变长的分配请求？这引出了管理空闲空间的策略、时间开销和空间开销等问题。

#### 17.1 假设

本章主要围绕用户级内存分配库（如 `malloc()` 和 `free()`）的历史和方法展开讨论。我们假设的接口类似于 `malloc()` 和 `free()` 提供的基本接口：

- `void *malloc(size_t size)`：接受一个表示字节数的参数 `size`，返回指向分配的内存块的指针。
- `void free(void *ptr)`：接受一个指针 `ptr`，释放对应的内存块。

**隐含意义**： 在释放空间时，用户不需要告知库这块空间的大小，因此库必须有办法在只传入一个指针的情况下确定该内存块的大小。

**堆和空闲列表**：

- **堆**：历史上，管理内存的区域被称为堆。
- **空闲列表**：用于管理堆中所有空闲块的引用的数据结构称为空闲列表（free list）。尽管它被称为“列表”，但它可以是任何一种能够追踪空闲空间的数据结构。

**碎片问题**： 本章主要关注外部碎片。内部碎片也可能存在，但为了简化讨论，主要讨论外部碎片。内部碎片是指当分配程序给出的内存块超出请求的大小时，未使用的空间造成的浪费。

**内存分配的不可移动性**： 我们假设一旦内存分配给程序，它就不能被移动。例如，当程序调用 `malloc()` 获取指向堆中内存块的指针时，这块内存就归该程序所有，直到程序调用 `free()` 归还它。因此，不可能通过紧凑化操作来减少碎片。

**连续的内存区域**： 假设分配程序管理的是一块连续的内存区域。在一些情况下，分配程序可能要求这块区域增长，但在本章中假设这块区域在整个生命周期内是固定大小的。

### 17.2 底层机制

本节深入探讨分配程序中普遍使用的基本机制，主要包括空间的分割与合并、追踪已分配空间的大小、以及如何利用空闲区域来维护空闲列表。

#### 分割与合并

**分割（Splitting）：** 空闲列表管理着未分配的内存块。当一个程序请求分配内存时，分配程序会检查空闲列表，找到足够大的块。如果找到的块比请求的内存大，那么分配程序会将该块分割为两部分：一部分返回给程序使用，另一部分继续留在空闲列表中。例如，假设一个空闲列表中有两个元素，分别记录着两个10字节的空闲块。当程序请求1字节的内存时，分配程序会从其中一个10字节的空闲块中切割出1字节分配给程序，剩余的9字节继续保留在空闲列表中。

**合并（Coalescing）：** 当程序释放内存时，分配程序会将这块内存重新加入空闲列表。如果这块内存与列表中现有的空闲块相邻，分配程序会将它们合并为一个更大的空闲块。例如，如果一个程序释放了堆中间的一块已分配空间，分配程序将检查它前后的空闲块，并将它们合并成一个更大的块，从而减少外部碎片。

#### 追踪已分配空间的大小

在 `free(void *ptr)` 函数中，分配程序需要知道要释放的内存块的大小。由于 `free()` 函数不接受大小参数，分配程序通常在内存块的头部（header）保存一些额外的信息，如块的大小和幻数（magic number）用于完整性检查。

**示例：** 假设用户请求分配20字节的内存，分配程序会在返回的内存块前面加上一个头块，记录这块内存的大小和其他相关信息。头块可能会包含以下结构：

```
c复制代码typedef struct header_t { 
 int size; 
 int magic; 
} header_t;
```

当用户调用 `free(ptr)` 时，分配程序会通过指针运算定位到头块，读取其中的大小信息，从而将该内存块正确地放回空闲列表。

#### 嵌入空闲列表

空闲列表是一种数据结构，用于记录堆中的空闲块。为了在空闲内存中维护这个列表，分配程序通常在空闲块中嵌入列表节点的信息。一个典型的空闲列表节点结构可能是：

```
c复制代码typedef struct node_t { 
 int size; 
 struct node_t *next; 
} node_t;
```

在空闲列表中，每个节点记录一个空闲块的大小和下一个空闲块的指针。

**示例：** 假设堆初始时大小为4096字节，只有一个空闲块。分配程序会初始化空闲列表，将这块空间记录为一个节点。这个节点可能会像这样初始化：

```
c复制代码node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, 
 MAP_ANON|MAP_PRIVATE, -1, 0); 
head->size = 4096 - sizeof(node_t); 
head->next = NULL;
```

如果程序请求100字节的内存，分配程序会在这个节点中分割出108字节（包括头块大小），返回给用户，并将剩余的空间继续保留在空闲列表中。

#### 合并后的例子

当用户程序释放内存块时，如果释放的块与现有的空闲块相邻，分配程序会将它们合并，减少碎片。例如，在一个包含3个已分配块的堆中，如果用户释放中间的块，分配程序会合并相邻的空闲块，形成一个更大的空闲块。

**示例：** 假设堆中的空闲块为：

- 一个100字节的空闲块
- 一个3764字节的空闲块

当用户释放中间的内存块时，分配程序会将其合并回空闲列表，使堆空间更连续和紧凑，减少碎片。

#### 让堆增长

当堆中的空闲空间耗尽时，分配程序通常会向操作系统请求更多的内存。通过 `sbrk` 或其他系统调用，分配程序可以扩大堆的大小，使得能够继续满足分配请求。如果无法获取更多的内存，分配程序会返回 `NULL`，表示分配失败。

------

通过这些底层机制，分配程序能够有效管理堆中的空闲空间，最大限度地减少碎片并优化内存使用。在接下来的讨论中，将进一步探讨这些机制的实际实现和优化策略。

### 17.3 基本策略

在内存分配中，管理空闲空间的策略决定了分配的效率和碎片的控制。下面介绍几种常见的基本策略，每种策略都有其独特的优缺点。

#### 最优匹配（Best Fit）

**描述：** 最优匹配策略试图找到最接近用户请求大小的空闲块。分配程序会遍历整个空闲列表，找到大小最接近且大于或等于请求大小的块，将其分配给用户，并返回剩余部分作为新的空闲块。

**优点：** 这种策略的优点是最大程度地减少了浪费，因为它总是选择最小的符合要求的空闲块，避免了大的内存块被划分成多个小块。

**缺点：** 由于需要遍历整个空闲列表，最优匹配的查找速度较慢。并且，最优匹配策略可能会产生许多小的无法使用的碎片（即内部碎片），尤其是在频繁的分配和释放操作后。

#### 最差匹配（Worst Fit）

**描述：** 最差匹配策略与最优匹配相反，它选择最大的空闲块，将其分配给用户。剩余部分作为新的空闲块继续留在空闲列表中。

**优点：** 最差匹配试图保留较大的空闲块，从而避免产生许多小的无法利用的碎片。

**缺点：** 尽管最差匹配保留了大块空闲空间，但它的表现通常很差，因为频繁的分割会导致过量的外部碎片。它的查找开销也很高，因为同样需要遍历整个空闲列表。

#### 首次匹配（First Fit）

**描述：** 首次匹配策略从空闲列表的头部开始，找到第一个能够满足请求的空闲块，将其分割并返回给用户，剩余部分作为新的空闲块继续留在列表中。

**优点：** 首次匹配的速度较快，因为它不需要遍历整个空闲列表，一旦找到合适的块就立即分配。

**缺点：** 首次匹配容易在列表的开头留下许多小的空闲块，导致列表的前部出现许多碎片。因此，首次匹配的空闲列表排序方式变得重要，通常使用按地址排序（address-based ordering）的方法，以便在释放内存时更容易合并相邻的空闲块。

#### 下次匹配（Next Fit）

**描述：** 下次匹配策略与首次匹配类似，但它不会每次都从空闲列表的头部开始查找，而是从上一次查找结束的位置继续。通过维护一个指针，分配程序可以在每次查找时从上次结束的位置继续，以均匀地利用整个空闲列表。

**优点：** 下次匹配可以避免频繁对空闲列表头部进行分割，从而减少前部产生碎片的几率。它的查找速度与首次匹配相近，且在分布上更加均匀。

**缺点：** 下次匹配的表现通常与首次匹配相似，但在某些情况下可能会导致较差的局部性。

#### 例子解析

考虑一个包含三个元素的空闲列表，长度依次为10、30、20。假设有一个15字节的内存请求，不同策略的表现如下：

- **最优匹配** 会遍历整个空闲列表，选择20字节的块，分配15字节后剩下5字节的空闲块。
- **最差匹配** 会选择最大的30字节块，分配15字节后剩下15字节的空闲块。
- **首次匹配** 会选择第一个足够大的块，也就是30字节块，分配15字节后剩下15字节的空闲块。

这些策略各有优缺点，具体选择取决于实际应用场景和需求。在实践中，可能需要对这些策略进行更深入的分析和优化，以适应不同的分配需求和工作负载。

### 17.4 其他方式

在内存分配策略的基础上，还有一些更高级的技术和算法，用来改进内存管理的效率和减少碎片。以下是几种常见的扩展方法：

#### 分离空闲列表（Segregated Free Lists）

**描述：** 分离空闲列表是一个有趣的方法，它的核心思想是为常见大小的内存请求维护单独的空闲列表。这意味着，如果一个应用程序经常请求某个特定大小的内存块，那么可以为这种大小的请求创建专门的列表，而不是使用通用的内存分配程序。

**优点：** 通过为常见的请求大小创建单独的列表，分离空闲列表能够有效减少碎片问题，因为这些内存块不会被其他大小的请求所打乱。此外，由于这些列表不需要复杂的查找过程，因此分配和释放内存的速度也很快。

**缺点：** 尽管分离空闲列表能够提高效率，但它也增加了系统的复杂性。特别是，在初始化时如何决定为哪些大小的内存请求创建专门的列表？如果分配给特定大小请求的内存不足，系统如何处理？

**示例：** Solaris 内核中使用的厚块分配程序（Slab Allocator）就是这种方法的一个实现。在 Solaris 系统中，为内核常用的对象（如锁、文件系统 inode 等）创建了对象缓存，这些对象缓存使用分离空闲列表来管理特定大小的内存块。当内存用尽时，分配程序可以向通用内存申请新的厚块（slab），以满足特定大小的请求。当对象不再使用时，内存块会被释放并返回到通用内存池。

#### 伙伴系统（Buddy System）

**描述：** 伙伴系统是一种旨在简化内存合并过程的分配算法。在这种系统中，空闲内存最初被视为一个大块（如 2^N 大小）。当有内存请求时，这个大块会被递归地一分为二，直到块的大小刚好满足请求。如果块被释放，系统会检查其“伙伴”块是否也空闲，如果是，则将它们合并成一个更大的块。

**优点：** 伙伴系统的优势在于合并过程非常高效。通过简单的地址计算可以快速确定两个块是否为“伙伴”，从而决定是否需要合并。这种方法可以有效减少外部碎片问题。

**缺点：** 伙伴系统的一个主要问题是它只支持 2 的幂次方大小的内存块分配，因此容易产生内部碎片（内存块内部未使用的部分）。此外，如果内存请求的大小不是 2 的幂次方，分配的内存块会比实际需要的要大，从而造成浪费。

**示例：** 考虑一个 64KB 大小的空闲内存块，用户请求 7KB 的内存，伙伴系统会将这个 64KB 的块递归分割成 32KB、16KB，直到产生一个 8KB 的块。这个 8KB 的块会被分配给用户，剩下的块继续留在空闲列表中。

#### 其他想法

**描述：** 除了上述方法，还有许多更复杂的内存分配技术，旨在提高分配速度和减少碎片。例如，平衡二叉树、伸展树、偏序树等数据结构都被用于改进内存分配的效率。这些数据结构通过优化空闲块的查找过程，提高了分配速度。

**多核系统的扩展：** 现代操作系统通常会运行多核处理器和多线程程序。为了在多核系统中提升分配程序的性能，人们提出了许多优化策略。例如，Berger 等人的方法和 Evans 的方法都是为了在多核系统中提高内存分配效率而设计的。

**挑战：** 内存分配器面临的一个持续挑战是如何在不同的工作负载下保持高效性和可扩展性。不同的应用程序对内存的使用方式各异，因此内存分配器需要灵活且高效地应对各种情况。

### 17.5 小结

在本章中，我们讨论了内存分配的基本策略以及一些高级的扩展方法。内存分配是现代计算机系统的一个关键组成部分，影响着系统的性能和效率。设计一个高效、灵活的内存分配器是一个复杂的任务，需要在多种策略之间进行权衡和优化。随着计算机系统的不断发展，内存分配器的设计也在不断演进，以适应新的挑战和需求。