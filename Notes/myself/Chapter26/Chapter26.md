### 第 26 章 并发：介绍

到目前为止，我们已经探讨了操作系统提供的各种基本抽象，例如将物理 CPU 转换为多个虚拟 CPU，以支持多个程序同时运行的假象，还探讨了如何通过虚拟内存的抽象为每个进程创建一个巨大的、私有的地址空间。通过这些机制，多个地址空间得以复用物理内存（或磁盘）。

本章将介绍一个新抽象：**线程（thread）**，这是为单个运行进程提供的并发机制。在传统的单线程程序中，只有一个执行点（即一个程序计数器，用来存放要执行的指令）。然而，在多线程程序中，会有多个执行点（多个程序计数器），每个执行点都用于获取指令并执行。换句话说，每个线程类似于一个独立的进程，唯一的区别是它们共享同一个地址空间，从而可以访问相同的数据。

#### 线程状态与进程状态的相似性

单个线程的状态与进程的状态非常相似。线程拥有一个程序计数器（PC），用于记录线程的执行位置。每个线程还有自己的一组寄存器，用于进行计算。如果两个线程在一个处理器上运行，从一个线程（T1）切换到另一个线程（T2）时，就会发生**上下文切换（context switch）**。线程间的上下文切换类似于进程间的上下文切换。不同之处在于，线程切换时地址空间保持不变，因此不需要切换页表。

#### 线程和进程之间的栈的差异

线程和进程的另一个主要区别在于栈。在传统的单线程进程中，只有一个栈，通常位于地址空间的一端（见图 26.1 左图）。然而，在多线程进程中，由于每个线程可以独立运行，并且可能会调用各种例程完成任务，因此每个线程都有自己的栈。这样，地址空间中可能存在多个栈（见图 26.1 右图）。这些栈中的变量、参数和返回值等会被放置在所谓的**线程本地存储（thread-local storage）** 中，即相关线程的栈中。

尽管多个栈可能会破坏地址空间的美感，但通常栈不会太大（除非大量使用递归的程序）。幸运的是，大多数程序并不需要使用太大的栈空间。

### 26.1 实例：线程创建

让我们通过一个简单的例子来演示如何创建线程。假设我们想运行一个程序，该程序创建两个线程，每个线程执行一些独立的任务，在这个例子中，分别打印 "A" 或 "B"。图 26.2 显示了代码。

```
c复制代码#include <stdio.h> 
#include <assert.h> 
#include <pthread.h> 

void *mythread(void *arg) { 
    printf("%s\n", (char *) arg); 
    return NULL; 
}

int main(int argc, char *argv[]) { 
    pthread_t p1, p2; 
    int rc; 
    printf("main: begin\n"); 
    rc = pthread_create(&p1, NULL, mythread, "A"); assert(rc == 0); 
    rc = pthread_create(&p2, NULL, mythread, "B"); assert(rc == 0); 
    rc = pthread_join(p1, NULL); assert(rc == 0); 
    rc = pthread_join(p2, NULL); assert(rc == 0); 
    printf("main: end\n"); 
    return 0; 
}
```

在这个程序中，主程序创建了两个线程，它们分别执行函数 `mythread()`，并传入不同的参数（"A" 或 "B"）。创建了两个线程（T1 和 T2）后，主程序调用 `pthread_join()`，等待特定的线程完成。

#### 可能的执行顺序

我们来看看这个程序可能的执行顺序。在表 26.1 中，时间是向下递增的，每一列展示了不同的线程（主线程、线程 1 或线程 2）的执行时刻。

| 主程序     | 线程 1 | 线程 2  |
| ---------- | ------ | ------- |
| 开始运行   |        |         |
| 打印“main” |        |         |
| 创建线程 1 |        |         |
| 创建线程 2 |        |         |
| 等待线程 1 | 运行   |         |
| 打印“A”    | 返回   |         |
| 等待线程 2 |        | 运行    |
|            |        | 打印“B” |
|            |        | 返回    |
| 打印“main” |        |         |

然而，这种执行顺序并不是唯一可能的顺序。不同的调度程序可能会导致不同的执行顺序。譬如，调度程序可能在线程创建后立即运行该线程，或决定以不同顺序运行线程。表 26.2 和 26.3 展示了不同的执行顺序。

#### 线程复杂性

通过这些例子可以看出，线程的使用让程序的执行顺序变得更加不可预测，从而使调试和理解程序变得更加困难。线程带来了强大的并发能力，但也使程序的行为更加复杂和难以预测。

总结起来，并发带来了巨大的灵活性和性能提升，但同时也增加了编程的复杂性。如何管理这种复杂性，如何确保线程之间的正确同步，是并发编程中的关键挑战。

### 26.2 为什么更糟糕：共享数据

上面的简单线程示例很好地展示了线程的创建以及它们如何根据调度程序的决定以不同的顺序运行。然而，它并没有展示当多个线程访问共享数据时如何相互作用。这种情况下，线程之间的相互作用可能导致一些非常棘手的问题。

让我们考虑一个简单的例子，其中两个线程试图更新一个全局共享变量。下面是代码示例，如图 26.3 所示：

```
c复制代码#include <stdio.h> 
#include <pthread.h> 
#include "mythreads.h" 

static volatile int counter = 0; 

// mythread()
// Simply adds 1 to counter repeatedly, in a loop 
// No, this is not how you would add 10,000,000 to 
// a counter, but it shows the problem nicely. 
void *mythread(void *arg) { 
    printf("%s: begin\n", (char *) arg); 
    int i; 
    for (i = 0; i < 1e7; i++) { 
        counter = counter + 1; 
    } 
    printf("%s: done\n", (char *) arg); 
    return NULL; 
} 

// main()
// Just launches two threads (pthread_create) 
// and then waits for them (pthread_join) 
int main(int argc, char *argv[]) { 
    pthread_t p1, p2; 
    printf("main: begin (counter = %d)\n", counter); 
    Pthread_create(&p1, NULL, mythread, "A"); 
    Pthread_create(&p2, NULL, mythread, "B"); 

    // join waits for the threads to finish 
    Pthread_join(p1, NULL); 
    Pthread_join(p2, NULL); 
    printf("main: done with both (counter = %d)\n", counter); 
    return 0; 
}
```

#### 代码说明

1. **线程封装：** 代码中使用了 `Pthread_create()` 和 `Pthread_join()` 进行线程创建和合并，并在失败时退出。这种封装便于处理错误，确保我们注意到任何潜在的问题。
2. **共享数据访问：** 在这段代码中，两个线程都尝试更新共享变量 `counter`，每个线程在循环中执行 1000 万次的加 1 操作。因此，理论上，最终的 `counter` 值应该是 2000 万。

#### 实验结果

在实际运行中，有时程序会如预期般工作，产生正确的结果：

```
bash复制代码prompt> gcc -o main main.c -Wall -pthread 
prompt> ./main 
main: begin (counter = 0) 
A: begin 
B: begin 
A: done 
B: done 
main: done with both (counter = 20000000)
```

然而，即使在单处理器上运行这段代码，也不一定会得到正确的结果。例如：

```
bash复制代码prompt> ./main 
main: begin (counter = 0) 
A: begin 
B: begin 
A: done 
B: done 
main: done with both (counter = 19345221)
```

甚至，结果可能每次都不同：

```
bash复制代码prompt> ./main 
main: begin (counter = 0) 
A: begin 
B: begin 
A: done 
B: done 
main: done with both (counter = 19221041)
```

#### 为什么会发生这种情况？

这类问题的核心在于**竞态条件（race condition）**。当多个线程并发地访问和修改共享数据时，调度程序的决策可能导致这些线程的操作交错执行，产生不确定的行为。特别是在这种情况下，`counter = counter + 1` 实际上并不是一个原子操作，而是由多个步骤组成：

1. 读取 `counter` 的当前值。
2. 计算新的值。
3. 将新值写回 `counter`。

如果两个线程交替执行这些步骤，很可能导致某个更新被覆盖，从而导致 `counter` 的最终值比预期的要小。

#### 提示：了解并使用工具

为了更好地理解和调试这种情况，你应该学习使用调试工具。例如，可以使用**反汇编程序**（如 `objdump`）来查看程序的汇编代码，理解底层指令是如何执行的。通过分析 `counter` 更新的底层代码，你可以更清楚地看到线程交替执行可能产生的竞态条件。

使用工具如 `gdb` 调试器或 `valgrind` 这样的内存分析器，可以帮助你更深入地了解程序的执行过程，并找到并发程序中的潜在问题。熟练掌握这些工具，将有助于你建立更健壮的并发程序。

### 26.3 核心问题：不可控的调度

为了理解为什么会发生前面提到的问题，我们需要了解编译器为更新共享变量 `counter` 生成的汇编代码序列。在这个例子中，我们的目标是让 `counter` 的值增加 1。以下是可能生成的代码序列（在 x86 架构下）：

```
assembly复制代码mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c
```

假设变量 `counter` 存储在内存地址 `0x8049a1c`。在这三条指令中，第一条指令使用 `mov` 指令将内存地址 `0x8049a1c` 中的值加载到寄存器 `eax` 中。然后，第二条指令将 `eax` 寄存器中的值加 1。最后，第三条指令将 `eax` 中的新值存回 `counter` 对应的内存地址。

#### 竞态条件的示例

假设线程 1 开始执行这段代码并将 `counter` 的值（假设初始值为 50）加载到它的 `eax` 寄存器中。此时，`eax` = 50。然后，线程 1 对 `eax` 执行加 1 操作，`eax` = 51。就在此时，系统触发了时钟中断，操作系统将线程 1 的状态保存到它的 TCB（线程控制块）中，并切换到线程 2。

现在，线程 2 开始执行相同的代码段。它首先将 `counter` 的当前值（仍为 50，因为线程 1 的更新尚未写回内存）加载到它的 `eax` 寄存器中。因此，线程 2 的 `eax` = 50。接着，线程 2 对 `eax` 执行加 1 操作，`eax` = 51，并将 `eax` 的值写回 `counter` 的内存地址。

随后，操作系统再次发生上下文切换，线程 1 恢复执行。此时，线程 1 的 `eax` = 51，并且准备将这个值写回 `counter` 对应的内存地址。结果，`counter` 的最终值仍然是 51，而不是预期的 52。

这种现象称为**竞态条件（race condition）**，即程序的行为依赖于多个线程的相对执行顺序。在竞态条件下，线程对共享资源的访问顺序不确定，可能导致数据不一致性或其他错误。

#### 临界区与互斥

这种代码段被称为**临界区（critical section）**，因为它是访问共享资源的部分代码。在临界区内，如果允许多个线程同时执行，可能会导致数据竞争和不一致性。因此，我们希望确保在任意时刻最多只有一个线程能执行临界区内的代码。

**互斥（mutual exclusion）**是我们期望的属性，它保证了当一个线程在临界区内执行时，其他线程将被阻止进入该临界区。实现互斥的一种常见方法是使用锁或其他同步原语，以确保同一时间只有一个线程能够访问共享资源。

#### 表 26.4：竞态条件的详细示例

为了更清楚地理解这个问题，我们可以逐步跟踪执行的指令序列：

| OS 操作      | 线程 1 执行指令       | 线程 1 状态 | 线程 2 执行指令       | 线程 2 状态 | `counter` 状态 |
| ------------ | --------------------- | ----------- | --------------------- | ----------- | -------------- |
| 在临界区之前 | -                     | -           | -                     | -           | 50             |
| `mov` 指令   | `mov 0x8049a1c, %eax` | `eax` = 50  | -                     | -           | 50             |
| `add` 指令   | `add $0x1, %eax`      | `eax` = 51  | -                     | -           | 50             |
| 中断         | 保存线程 1 的状态     | -           | 恢复线程 2 的状态     | -           | 50             |
| `mov` 指令   | -                     | -           | `mov 0x8049a1c, %eax` | `eax` = 50  | 50             |
| `add` 指令   | -                     | -           | `add $0x1, %eax`      | `eax` = 51  | 50             |
| `mov` 指令   | -                     | -           | `mov %eax, 0x8049a1c` | `eax` = 51  | 51             |
| 中断         | 保存线程 2 的状态     | -           | 恢复线程 1 的状态     | -           | 51             |
| `mov` 指令   | `mov %eax, 0x8049a1c` | `eax` = 51  | -                     | -           | 51             |

最终，尽管线程 1 和线程 2 都尝试将 `counter` 增加 1，但由于竞态条件的存在，`counter` 的最终值仍然是 51，而不是预期的 52。

#### 互斥与 Dijkstra

为了避免竞态条件，我们需要确保在执行临界区代码时只有一个线程能够进入，这就是所谓的互斥。Edgar Dijkstra 是这个领域的重要先驱，他创造了很多相关的术语和概念，并提出了早期解决并发问题的方法。

在接下来的章节中，我们将讨论如何使用各种同步原语（如锁、信号量等）来实现互斥，从而避免竞态条件。

### 26.4 原子性愿望

解决共享数据访问中的竞态条件问题的一种方法是使用更强大的指令，使得某些操作可以在单个步骤中完成，从而消除在执行这些操作时发生不合时宜的中断的可能性。例如，假设我们有一条超级指令：

```
assembly
复制代码
memory-add 0x8049a1c, $0x1
```

这条假想的指令将一个值添加到指定的内存位置，并且硬件保证它以原子方式（atomic）执行。这意味着在指令执行过程中，不会发生中断，操作要么完全发生，要么完全不发生——没有中间状态。这样的硬件支持将非常有用。

### 原子操作的概念

“原子性”意味着“作为一个单元”操作。有时我们说这是“全部或没有”的操作。我们希望能够以原子方式执行以下三条指令的序列：

```
assembly复制代码mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c
```

然而，在大多数情况下，硬件不提供这样高级别的原子操作指令。设想你正在构建一个并发的 B 树结构，并希望更新它。我们很难期待硬件提供“B 树的原子性更新”这样的复杂指令集。

### 同步原语的引入

因此，操作系统和多线程程序通常依赖于硬件提供的更基础的同步原语（synchronization primitives），如锁（locks）、信号量（semaphores）和条件变量（condition variables），这些原语可以用来构建更复杂的、确保正确性的同步操作。通过使用这些同步原语，结合操作系统的支持，开发者可以编写多线程代码，使其在访问临界区时避免竞态条件，确保产生正确的结果。

### 关键并发术语

在讨论并发编程时，有几个重要术语需要掌握：

- **临界区（critical section）**：指访问共享资源的代码片段，该资源通常是一个变量或数据结构。为了避免数据竞争，必须确保每次只有一个线程进入临界区。
- **竞态条件（race condition）**：当多个线程同时进入临界区并试图更新共享数据时，可能会导致意外的结果。竞态条件使程序的行为依赖于线程的执行顺序，而这种顺序在多线程环境中是不可预测的。
- **不确定性（indeterminate behavior）**：程序的输出在不同的运行中可能不同，具体取决于线程在何时执行。竞态条件导致程序的输出不再是确定的。
- **互斥（mutual exclusion）**：为了解决竞态条件，程序必须确保每次只有一个线程进入临界区。通过使用锁等同步原语来实现互斥，程序可以避免竞态条件，确保其行为是确定的。

### 核心问题：如何实现同步

为了实现有效的同步，我们需要硬件提供基础的同步原语，并在操作系统层面上正确地利用这些原语。接下来的讨论将深入研究如何在硬件和操作系统的支持下，构建和使用同步原语来确保多线程程序的正确性。

### 26.5 还有一个问题：等待另一个线程

除了确保原子性，线程之间还有另一种常见的交互形式：一个线程在继续执行之前必须等待另一个线程完成某项操作。这种情况在多线程编程中非常普遍，例如，一个线程可能需要等待另一个线程完成 I/O 操作后再继续执行。对于这种交互，操作系统提供了如条件变量（condition variables）之类的机制，以便线程可以协调它们的执行顺序。

### 26.6 小结：为什么操作系统课要研究并发

并发是操作系统的重要组成部分，因为操作系统本身就是第一个并发程序。它必须管理多个进程和线程，确保系统的稳定性和性能。随着计算机系统的演进，应用程序也逐渐变得多线程化，开发者必须考虑到并发带来的复杂性。因此，理解并发问题以及如何通过操作系统来管理并发，是操作系统课程的重要内容。

通过学习操作系统中的并发管理，我们可以更好地理解和解决多线程编程中的挑战，并运用这些知识构建健壮的多线程应用程序。